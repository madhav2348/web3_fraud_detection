{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN/mYPuTUywOm/UPAsmxSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhav2348/web3_fraud_detection/blob/main/web3_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "tHwtI86DDv4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdCBU9z7Dy77",
        "outputId": "120f1116-3cdc-4edb-e283-d9d5ca8de759",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d chusmman/synthetic-cryptoweb3-transaction-dataset\n",
        "!unzip synthetic-cryptoweb3-transaction-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR8xf40KD0we",
        "outputId": "aa056ddf-1b6e-4b97-bcbd-07aeb072be85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/chusmman/synthetic-cryptoweb3-transaction-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading synthetic-cryptoweb3-transaction-dataset.zip to /content\n",
            "  0% 0.00/51.4M [00:00<?, ?B/s]\n",
            "100% 51.4M/51.4M [00:00<00:00, 1.08GB/s]\n",
            "Archive:  synthetic-cryptoweb3-transaction-dataset.zip\n",
            "  inflating: crypto_transactions.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbvtcBDZDCE3"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Config\n",
        "CSV = \"crypto_transactions.csv\"\n",
        "ARTIFACT_DIR = \"artifacts\"\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "ANOMALY_OUTPUT = \"anomalies_review.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(CSV)\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])"
      ],
      "metadata": {
        "id": "5bJahW1JDOzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering Function\n",
        "def featurize(df_in, fit_encoders=None):\n",
        "    df = df_in.copy()\n",
        "\n",
        "    # Extract time-based features\n",
        "    df['year']  = df['timestamp'].dt.year\n",
        "    df['month'] = df['timestamp'].dt.month\n",
        "    df['day']   = df['timestamp'].dt.day\n",
        "    df['hour']  = df['timestamp'].dt.hour\n",
        "\n",
        "    # Categorical and numerical columns\n",
        "    cat_cols = ['from_wallet','to_wallet','token','platform','tx_type']\n",
        "    num_cols = ['amount','gas_fee_usd','year','month','day','hour']\n",
        "\n",
        "    # Encode categories into numbers\n",
        "    if fit_encoders is None:\n",
        "        enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "        enc.fit(df[cat_cols])\n",
        "    else:\n",
        "        enc = fit_encoders\n",
        "\n",
        "    cat_encoded = enc.transform(df[cat_cols])\n",
        "    cat_encoded_df = pd.DataFrame(cat_encoded, columns=cat_cols, index=df.index)\n",
        "\n",
        "    # Combine numerical + encoded categorical features\n",
        "    X = pd.concat([df[num_cols].reset_index(drop=True),\n",
        "                   cat_encoded_df.reset_index(drop=True)], axis=1)\n",
        "    return X, enc, num_cols + cat_cols"
      ],
      "metadata": {
        "id": "4fOXrLo-DQMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Training Data\n",
        "X, encoder, feature_cols = featurize(df)\n",
        "\n",
        "# Scale features so models work better\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "AoUf1SCnDWw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Models"
      ],
      "metadata": {
        "id": "rbq4T_DXEcWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolation Forest\n",
        "iso = IsolationForest(n_estimators=200, contamination=0.01, random_state=42)\n",
        "iso.fit(X_scaled)\n",
        "iso_labels = iso.predict(X_scaled)\n",
        "iso_scores = iso.decision_function(X_scaled)"
      ],
      "metadata": {
        "id": "MXpF7WafEjGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Local Outlier Factor (novelty=True allows later prediction)\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01, novelty=True)\n",
        "lof.fit(X_scaled)\n",
        "lof_labels = lof.predict(X_scaled)\n",
        "lof_scores = lof.decision_function(X_scaled)"
      ],
      "metadata": {
        "id": "Xw1FZQBADYhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['iso_anomaly'] = iso_labels\n",
        "df['lof_anomaly'] = lof_labels\n",
        "df['iso_score'] = iso_scores\n",
        "df['lof_score'] = lof_scores"
      ],
      "metadata": {
        "id": "5W6-PZ9jHKcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization"
      ],
      "metadata": {
        "id": "CAml-cx2Hadu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(df[df['iso_anomaly'] == 1]['amount'], bins=50, alpha=0.6, label='Normal')\n",
        "plt.hist(df[df['iso_anomaly'] == -1]['amount'], bins=50, alpha=0.6, label='Anomaly')\n",
        "plt.xlabel('Transaction Amount')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Amounts (Isolation Forest)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rNdFOYZ-HfOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(df['amount'], df['gas_fee_usd'], c=(df['iso_anomaly'] == -1), cmap='coolwarm', alpha=0.5)\n",
        "plt.xlabel('Amount')\n",
        "plt.ylabel('Gas Fee (USD)')\n",
        "plt.title('Amount vs Gas Fee — Red = Anomalies')\n",
        "plt.colorbar(label='Anomaly Flag')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0XXAHOmEHq3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(pd.crosstab(df['iso_anomaly'], df['lof_anomaly']), annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('LOF Anomaly')\n",
        "plt.ylabel('Isolation Forest Anomaly')\n",
        "plt.title('Model Agreement Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_uwRihAdJFcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model for later\n",
        "\n",
        "joblib.dump(encoder, os.path.join(ARTIFACT_DIR, \"ordinal_encoder.joblib\"))\n",
        "joblib.dump(scaler, os.path.join(ARTIFACT_DIR, \"scaler.joblib\"))\n",
        "joblib.dump(iso, os.path.join(ARTIFACT_DIR, \"isolation_forest.joblib\"))\n",
        "joblib.dump(lof, os.path.join(ARTIFACT_DIR, \"lof_novelty.joblib\"))"
      ],
      "metadata": {
        "id": "xSOxRMwXDbnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZVzDtIE2bmC"
      },
      "outputs": [],
      "source": [
        "# Real Time Transcation process\n",
        "def process_transaction(tx: dict,\n",
        "                        encoder_path=os.path.join(ARTIFACT_DIR, \"ordinal_encoder.joblib\"),\n",
        "                        scaler_path=os.path.join(ARTIFACT_DIR, \"scaler.joblib\"),\n",
        "                        iso_path=os.path.join(ARTIFACT_DIR, \"isolation_forest.joblib\"),\n",
        "                        lof_path=os.path.join(ARTIFACT_DIR, \"lof_novelty.joblib\"),\n",
        "                        output_csv=ANOMALY_OUTPUT,\n",
        "                        anomaly_threshold=None):\n",
        "\n",
        "    # Load saved models\n",
        "    enc = joblib.load(encoder_path)\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    iso = joblib.load(iso_path)\n",
        "    lof = joblib.load(lof_path)\n",
        "\n",
        "    # Convert to DataFrame and extract features\n",
        "    tx_df = pd.DataFrame([tx])\n",
        "    tx_df['timestamp'] = pd.to_datetime(tx_df['timestamp'])\n",
        "    X_tx, _, cols = featurize(tx_df, fit_encoders=enc)\n",
        "    X_tx_scaled = scaler.transform(X_tx)\n",
        "\n",
        "    # Predict with both models\n",
        "    iso_label = iso.predict(X_tx_scaled)[0]\n",
        "    iso_score = iso.decision_function(X_tx_scaled)[0]\n",
        "    lof_label = lof.predict(X_tx_scaled)[0]\n",
        "    lof_score = lof.decision_function(X_tx_scaled)[0]\n",
        "\n",
        "    # Combine results\n",
        "    combined_score = (iso_score + lof_score) / 2.0\n",
        "    flagged = (iso_label == -1) or (lof_label == -1)\n",
        "    if anomaly_threshold is not None:\n",
        "        flagged = flagged or (combined_score < anomaly_threshold)\n",
        "\n",
        "    # Save flagged tx for review\n",
        "    if flagged:\n",
        "        out_df = pd.DataFrame([{**tx,\n",
        "                                \"iso_label\": int(iso_label),\n",
        "                                \"iso_score\": float(iso_score),\n",
        "                                \"lof_label\": int(lof_label),\n",
        "                                \"lof_score\": float(lof_score),\n",
        "                                \"combined_score\": float(combined_score),\n",
        "                                \"flagged\": True}])\n",
        "        header = not os.path.exists(output_csv)\n",
        "        out_df.to_csv(output_csv, mode='a', index=False, header=header)\n",
        "\n",
        "    return {\n",
        "        \"iso_label\": iso_label,\n",
        "        \"iso_score\": iso_score,\n",
        "        \"lof_label\": lof_label,\n",
        "        \"lof_score\": lof_score,\n",
        "        \"combined_score\": combined_score,\n",
        "        \"flagged\": flagged\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "b1RsuJFaJOBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "example_results = []\n",
        "for i, row in df.head(5).iterrows():\n",
        "    tx = {\n",
        "        \"tx_hash\": row['tx_hash'],\n",
        "        \"from_wallet\": row['from_wallet'],\n",
        "        \"to_wallet\": row['to_wallet'],\n",
        "        \"token\": row['token'],\n",
        "        \"amount\": float(row['amount']),\n",
        "        \"timestamp\": row['timestamp'].isoformat(),\n",
        "        \"gas_fee_usd\": float(row['gas_fee_usd']),\n",
        "        \"platform\": row['platform'],\n",
        "        \"tx_type\": row['tx_type']\n",
        "    }\n",
        "    res = process_transaction(tx)\n",
        "    example_results.append(res)\n",
        "\n",
        "pd.DataFrame(example_results)\n"
      ],
      "metadata": {
        "id": "cO59GR0aDieh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}